<!DOCTYPE html>
<html>
<head>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/opencv.js"></script> <!-- OpenCV.js -->
</head>
<body>
  <video id="input_video" autoplay playsinline></video>
  <canvas id="output_canvas"></canvas>

  <script>
    const video = document.getElementById('input_video');
    const canvas = document.getElementById('output_canvas');
    const ctx = canvas.getContext('2d');

    const faceMesh = new FaceMesh({locateFile: f => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${f}`});
    faceMesh.setOptions({maxNumFaces:1, refineLandmarks:true});
    faceMesh.onResults(onResults);

    const camera = new Camera(video, {
      onFrame: async () => await faceMesh.send({image: video}),
      width: 640, height: 480
    });
    camera.start();

    function onResults(results) {
      ctx.save();
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      if (!results.multiFaceLandmarks) {ctx.restore(); return;}
      const lm = results.multiFaceLandmarks[0];

      // OpenCV solvePnP用の対応点（サンプル: nose tip=1, chin=152 などを選定）
      const imagePts = cv.matFromArray(6,1,cv.CV_64FC2, [
        lm[1].x*canvas.width, lm[1].y*canvas.height,
        lm[152].x*canvas.width, lm[152].y*canvas.height,
        lm[33].x*canvas.width, lm[33].y*canvas.height,
        lm[263].x*canvas.width, lm[263].y*canvas.height,
        lm[61].x*canvas.width, lm[61].y*canvas.height,
        lm[291].x*canvas.width, lm[291].y*canvas.height
      ]);
      const modelPts = cv.matFromArray(6,1,cv.CV_64FC3, [
        0,0,0,
        0,-330,-65,
        -225,170,-135,
        225,170,-135,
        -150,-150,-125,
        150,-150,-125
      ]);
      const cameraMatrix = cv.matFromArray(3,3,cv.CV_64FC1, [f,0,cx, 0,f,cy, 0,0,1]);
      const distCoeffs = cv.Mat.zeros(4,1,cv.CV_64FC1);
      let rvec = new cv.Mat(), tvec = new cv.Mat();
      cv.solvePnP(modelPts, imagePts, cameraMatrix, distCoeffs, rvec, tvec);

      // ベクトル描画
      let noseEnd3D = cv.matFromArray(1,1,cv.CV_64FC3, [0,0,1000]);
      let noseEnd2D = new cv.Mat();
      cv.projectPoints(noseEnd3D, rvec, tvec, cameraMatrix, distCoeffs, noseEnd2D);

      const p1 = [lm[1].x*canvas.width, lm[1].y*canvas.height];
      const p2 = [noseEnd2D.data64F[0], noseEnd2D.data64F[1]];
      ctx.beginPath();
      ctx.moveTo(...p1);
      ctx.lineTo(...p2);
      ctx.strokeStyle = "red";
      ctx.lineWidth = 3;
      ctx.stroke();

      // リソース解放
      imagePts.delete(); modelPts.delete(); cameraMatrix.delete();
      distCoeffs.delete(); rvec.delete(); tvec.delete(); noseEnd3D.delete(); noseEnd2D.delete();

      ctx.restore();
    }
  </script>
</body>
</html>
