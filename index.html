<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>MediaPipe Head Pose Estimation</title>
  <!-- vision_bundle CDN -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/vision_bundle.js"></script>
  <!-- OpenCV.js（solvePnP用） -->
  <script src="https://docs.opencv.org/master/opencv.js"></script>
  <style>
    video, canvas { position: absolute; width: 640px; height: 480px; }
  </style>
</head>
<body>
  <video id="input_video" autoplay playsinline></video>
  <canvas id="output_canvas"></canvas>

  <script>
    const video = document.getElementById('input_video'), canvas = document.getElementById('output_canvas');
    const ctx = canvas.getContext('2d');

    async function init() {
      const vision = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/vision_bundle.wasm");
      const faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
        baseOptions: { modelAssetPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/model/face_landmarker.task' },
        runningMode: 'VIDEO',
        outputFacialTransformationMatrixes: true
      });

      navigator.mediaDevices.getUserMedia({ video: true }).then(stream => {
        video.srcObject = stream;
        video.onloadedmetadata = () => { canvas.width = video.videoWidth; canvas.height = video.videoHeight; renderFace(); };
      });

      async function renderFace() {
        ctx.drawImage(video, 0, 0);
        const result = faceLandmarker.detectForVideo(video, performance.now());
        if (result.faceTransformMatrixes && result.faceTransformMatrixes.length > 0) {
          const m = result.faceTransformMatrixes[0].asMatrix(); // 4x4
          // m の値から yaw/pitch/roll を算出（行列→Quaternion→Eulerなど）
          console.log('Matrix:', m);
        }
        requestAnimationFrame(renderFace);
      }
    }
    init();
  </script>
</body>
</html>
